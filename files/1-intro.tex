%\cleardoublepage
\chapter{Introducción}
\label{sec:intro}
\pagenumbering{arabic} 

El aprendizaje automático (\emph{Machine Learning} en inglés) es una rama de la inteligencia artificial y la ciencia computacional que se centra en el uso de datos y algoritmos para imitar la forma en la que los humanos aprenden con el objetivo de aumentar gradualmente su precisión.
Es un componente fundamental del campo de la ciencia de datos, cuya importancia ha experimentado un gran crecimiento recientemente. 
El aprendizaje automático hace uso de métodos estadísticos para entrenar algoritmos que hacen clasificaciones o predicciones y que permiten descubrir piezas clave de información dentro de proyectos de procesamiento de datos. 
Esta información afecta posteriormente en la toma de decisiones dentro de distintas aplicaciones y negocios, con una gran capacidad de impactar en el crecimiento de los mismos.

\section{Aprendizaje automático y consumo energético}

Gracias al desarrollo de nuevas tecnologías computacionales, el aprendizaje automático que se utiliza hoy en día es muy diferente de como era en el pasado.
El modelo actual surgió del reconocimiento de patrones y de la teoría de que los ordenadores pueden aprender sin necesidad de ser programados para resolver tareas específicas, cuando los investigadores interesados en la inteligencia artificial se empezaron a plantear si los ordenadores serían capaces de aprender a partir de datos.
De aquí surge la importancia del aspecto iterativo de este aprendizaje, que permite que el sistema se adapte de forma independiente cada vez que nuevos datos son incorporados y sea capaz de aprender de cada computación previa para producir decisiones y resultados que sean confiables y repetibles.

Es así que, aunque una gran parte de los algoritmos utilizados en el aprendizaje automático son conocidos desde hace relativamente bastante tiempo, la habilidad de aplicar automáticamente complejos cálculos matemáticos a grandes cantidades de datos una y otra vez, cada vez más rápidamente, es un desarrollo muy reciente conseguido gracias a los avances en componentes informáticos y la disminución de costes de grandes sistemas computacionales con enormes capacidades de memoria y procesamiento.
Este es especialmente el caso para el campo del aprendizaje profundo (\emph{deep learning}), donde los modelos han crecido en cálculos para llegar a alcanzar típicamente el orden de los GigaFlops y en requisitos de memoria que se encuentran típicamente en el orden de los millones de parámetros.

Sin embargo, este gran poder de procesamiento trae consigo un gran gasto energético.
El consumo de energía en la arquitectura de computadores ha sido foco de atención de investigadores interesados en obtener procesadores eficientes energéticamente de última generación durante décadas. 
Por otro lado, los investigadores interesados en el aprendizaje automático se han centrado principalmente en la producción de modelos cada vez más profundos y precisos, sin poner ningún límite en términos computacionales más allá de la disponibilidad de procesadores capaces.

%%%%%%%%%%%%%%%%%%

En el ámbito de los grandes modelos de aprendizaje, como los modelos de lenguaje (e.g., GPT-3), visión por computador y el aprendizaje en la nube, el impacto energético es particularmente elevado. Los grandes modelos de lenguaje, por ejemplo, requieren enormes cantidades de datos y recursos computacionales para su entrenamiento, lo que se traduce en un consumo energético considerable. Del mismo modo, las aplicaciones de visión por computador, especialmente aquellas que involucran redes convolucionales profundas (CNN), también son intensivas en energía. El aprendizaje en la nube agrava estos problemas al trasladar el consumo energético a los centros de datos, que pueden tener diferentes niveles de eficiencia y fuentes de energía.

Los grandes modelos de aprendizaje, como los modelos de lenguaje de gran escala (large language models, LLMs), han mostrado un impacto significativo en el consumo energético debido a su tamaño y complejidad. GPT-3, uno de los modelos más conocidos, cuenta con 175 mil millones de parámetros y requiere una cantidad masiva de energía para su entrenamiento. Los modelos de visión por computador, como las redes neuronales convolucionales (CNNs) y sus variantes más profundas, también consumen cantidades sustanciales de energía durante el entrenamiento y la inferencia.

El uso de aprendizaje en la nube, aunque ofrece flexibilidad y escalabilidad, puede tener implicaciones negativas para el consumo energético. Los centros de datos que alimentan estos servicios requieren grandes cantidades de electricidad, y su impacto depende en gran medida de la fuente de energía utilizada. Algunos centros de datos están migrando hacia fuentes de energía renovable para mitigar este impacto, pero la transición no es uniforme en todas las regiones.

% MORE Por qué clasificación, menciones a otros proyectos de análisis energético
% CITE https://www.sciencedirect.com/science/article/pii/S0743731518308773#b18

\section{Desarrollo de una aplicación comparativa: \emph{MLCost}}

\todoin{
Introducción a la aplicación desarrollada
}



\section{Objetivos del proyecto}
\label{sec:objetivos}

\subsection{Objetivo general} % título de subsección (se muestra)
\label{sec:objetivo-general} % identificador de subsección (no se muestra, es para poder referenciarla)


Este Trabajo de Fin de Grado tiene como objetivo crear una herramienta que permita la comparación sistemática del consumo energético y el impacto de la huella de carbono en los modelos más representativos de técnicas de clasificación de aprendizaje automático supervisado.


\subsection{Objetivos específicos}
\label{sec:objetivos-especificos}

Para esta finalidad se han tenido en cuenta los siguientes objetivos específicos:

    \begin{itemize}
        \item Estudiar las herramientas disponibles para aprendizaje automático.
        \item Estudiar el uso de herramientas de medida del consumo energético.
        \item Comparar el consumo energético en los algoritmos de clasificación más importantes.
        \item Analizar la relación entre la precisión de los modelos y su consumo energético en conjuntos de datos de distintos tamaños y características.
    \end{itemize}

% \section{Planificación temporal}
% \label{sec:planificacion-temporal}

% \todo[inline]{Completar con información temporal de Clockify}

\section{Estructura de la memoria}
\label{sec:estructura}

%% al final %%
\todo[inline]{TODO: estructura}

%\cleardoublepage